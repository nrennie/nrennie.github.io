[
  {
    "path": "posts/2021-12-18-thinking-about-tidytuesday-and-the-spice-girls/",
    "title": "Thinking about #TidyTuesday (and the Spice Girls)",
    "description": "Earlier this week, whilst curating for @WeAreRLadies, I tweeted a thread on my thought process for this week's #TidyTuesday challenge. This blog post expands on the thoughts in that thread.",
    "author": [
      {
        "name": "Nicola Rennie",
        "url": {}
      }
    ],
    "date": "2021-12-18",
    "categories": [],
    "contents": "\r\nEarlier this week, whilst curating for @WeAreRLadies, I tweeted a thread on my thought process for this week’s #TidyTuesday challenge. This blog post expands on the thoughts in this aforementioned thread:\r\n\r\nIt can be a little bit scary to make your first (or any) contribution to #TidyTuesday on twitter so I thought I’d outline my thought process for this week’s Spice Girls data. pic.twitter.com/zsyV3mfRkG— We are R-Ladies (@WeAreRLadies) December 14, 2021\r\n\r\n\r\nFor those of you who don’t know, #TidyTuesday is a weekly data challenge aimed at the R community. Every week a new dataset is posted alongside a chart or article related to that dataset, and ask participants explore the data. You can access the data and find out more here.\r\nIt can be a little bit scary to make your first (or any) contribution to #TidyTuesday on twitter especially when the quality of the submissions you see is so high. So I thought I’d outline my thought process for this week’s Spice Girls data.\r\n\r\n\r\n\r\nFigure 1: Image from tenor.com/view/wannabe-spice-girls-gif-13245102\r\n\r\n\r\n\r\nExploring the data\r\nThis week there are actually three different data sets. Although this can be a good opportunity to practice different types of joins of dataframes, to avoid getting overwhelmed, it might be a good idea to just focus on one of these data sets. I’m going to focus on the studio_album_tracks data.\r\nReading the data dictionary provided with the data set is usually my first step. Variables aren’t always named the most useful things (although they are this week!) and this helps me understand what the data actually is. There are quite a lot of variables in this data set.\r\nSince I come from a time series/forecasting background, the first thing that catches my eye is the album_release_date. However, (sadly) the Spice Girls only released three albums so it’s not quite enough time periods to look at time dependence.\r\nThere are quite a lot of variables with values between 0 and 1 e.g. danceability, energy, … This makes me think that a spider plot (AKA radar plot) might be appropriate. I also keep a list of plot types/packages that I’d like to experiment with and spider plots are one of the chart types on my list. I’ve never made a spider plot in R before so this will be a learning experience for me too. Not everyone is a fan of spider plots but it’s still useful to learn new things.\r\nBuilding a basic plot\r\nSo let’s make a spider plot showing the average danceability, energy, speechiness, acousticness, instrumentalness, liveness, valence for each of the albums released.\r\nTo start off plotting, I usually pull out the variables that I’m going to use by using select() from {dplyr}. Then I use group_by() and summarise_if() to calculate the mean of each of my variables.\r\nNow for the fun part – plotting! There isn’t a built in geom within {ggplot2} to create spider plots, so it’s off to Google I go. The {ggradar} package on GitHub by [@ricardobion](https://twitter.com/ricardobion) is compatible with {ggplot2} so it seems like a viable option.\r\n\r\n\r\n\r\nI now have a basic spider plot, and I can get started think a bit about design.\r\nMaking it look pretty\r\nViewing the help files for the package (or function) are really useful in helping me to decide what elements of the spider plot I can customise easily.\r\nAlthough extra graphics are always fun, spiders plots are already quite complex to read so I decide on a minimalist theme. Most of this, if not all will be done using just {ggplot2} functions. The theme() options are the most useful.\r\nI add some captions, including some a subtitle (or tag) to explain what the plot tells a viewer. In terms of choosing a colour scheme, I like to choose something related to the data. This week’s data is perfect for using the Spice Girls palette from the {popthemes} package from [@_johnmackintosh](https://twitter.com/_johnmackintosh). There doesn’t seem to be an option to change the axis label colour in ggradar so I may add these labels in a different colour later using an annotation layer.\r\nNow the only thing left to do is post the final version to twitter with the #TidyTuesday hashtag.\r\n\r\n\r\n\r\nThe code for this plot is on GitHub if you want to play around with it and create your own version.\r\nFinal Thoughts\r\nI’ll blog about my experience of curating in a later post, but for now I hope that sharing my process for creating a data visualisation has been helpful. Why don’t you participate in your first TidyTuesday if you haven’t already?\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-12-18-thinking-about-tidytuesday-and-the-spice-girls/images/final_plot.jpeg",
    "last_modified": "2021-12-18T14:52:48+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-12-01-30-day-map-challenge-2021/",
    "title": "30 Day Map Challenge 2021",
    "description": "The #30DayMapChallenge is a daily mapping, cartography, and data visualization challenge aimed at the spatial community.",
    "author": [
      {
        "name": "Nicola Rennie",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [],
    "contents": "\r\nThe #30DayMapChallenge is a daily mapping, cartography, and data visualization challenge aimed at the spatial community. Every day in November participants create a map with a given theme (e.g. population, monochrome, raster) and share their results Twitter using the #30DayMapChallenge hashtag. Check out the challenge here.\r\n\r\n\r\n\r\nAlthough I’ve been creating data visualisations for a while, I don’t normally have that many opportunities to work with spatial data. This year, I created all 30 maps (see below). You can view all of my maps (and the code used to generate them) at: github.com/nrennie/30DayMapChallenge.\r\nFinding and processing data\r\nOne of the things that set the 30 Day Map Challenge apart from other data visualisation challenges I’ve participated in (like TidyTuesday, for example) was the lack of data. Not only did the challenge involve making 30 maps, it also involved deciding what to map and finding the relevant data. To make this part a little less intimidating, I focused most of my maps around Glasgow, Scotland, and the UK. This meant I could use the same base maps multiple times, and sometimes the same data. Unlike challenges where data is provided, most of the data I found “in the wild” wasn’t in a nice format. For example, I also learnt how to read in .tif and .asc files, and convert them into a format that R would understand.\r\nUseful and interesting packages\r\nMost of my maps were created using R, with the exception of days 14 and 15, which used Tableau and some watercolour paints (separately!). Although I’m very familiar with R and its various data visualisation tools, I discovered a number of new packages that I hadn’t used before. A few highlights:\r\nFor plotting:\r\n{roughsf}: an R package for plotting spatial objects in a hand-drawn, sketch style.\r\n{rayshader}: an R package for producing (realistic) 2D and 3D data visualizations in R using elevation data.\r\n{rcartocolor}: a set of discrete and continuous colour palettes with colourblind friendly options.\r\n{MapColoring}: an R package for assigning colors to polygon maps such that no two adjacent features have the same color, while using a minimal number of colors.\r\nFor data:\r\n{osmdata}: an R package for downloading and using data from OpenStreetMap.\r\n{osrm}: an R package for OSRM (a routing service based on OpenStreetMap data) which computes routes, trips, isochrones and travel distances and times.\r\n{rgeoboundaries}: an R package for the geoBoundaries API, providing country political administrative boundaries.\r\n{elevatr}: an R package which provides elevation data from Amazon Web Services Terrain Tiles, Open Topography Global Datasets, and the USGS Elevation Point Query Service.\r\nMy Favourite Map\r\nMy favourite map from the challenge was Day 9 (monochrome). This is a circular map of the roads and streets in Glasgow with data obtained from the {osmdata} package. I really liked the simplicity of this map, and that you can clearly see the river in the negative space, even without explicitly plotting it.\r\n\r\n\r\n\r\nThis one was mostly inspired by Abdoul Madjid. This was the first time I’d looked at intersections between different spatial objects (something I’d been meaning to learn for a while). Being restricted to monochrome colours also meant I didn’t spend too much time thinking about colour palettes, and could instead focus on the data.\r\nFavourite Maps on Twitter\r\nI saw so many cool maps in November, and it’s impossible to list them all, but here are a few I really liked:\r\nDay 19 (Islands) by Kate Ellen\r\n\r\nKept it really simple for day 19 - islands, a 3D view of stunning Halong Bay in Vietnam. #30DayMapChallenge pic.twitter.com/vphKf0wNlH— Kate (@KateEllen100) November 19, 2021\r\n\r\n\r\nDay 26 (Choropleth) by Colin Angus\r\n\r\n#30DayMapChallengeDay 26: Choropleth mapI thought I'd revisit an old bivariate map, showing rates of deaths due to drugs and alcohol across the UK.So many tragic stories here, but Scotland really stands out. pic.twitter.com/rdEBoApur3— Colin Angus (@VictimOfMaths) November 26, 2021\r\n\r\n\r\nDay 20 (Movement) by Dan Harris\r\n\r\n#30DayMapChallenge day 20 - movement. Drive times to @LEGO_Group stores in the UK, which I would like to propose as a new indicator of rural deprivation. pic.twitter.com/vcFcP06zoG— Dan Harris (@DiasporaDan) November 20, 2021\r\n\r\n\r\nFinal Thoughts\r\nI definitely learnt a lot of new ways to visualise spatial data in the last 30 days, including some new packages. I also learnt a lot about Glasgow, and the country I was born in through exploring new sources of data. Next year, I’d like to be more selective about which days to participate in. Rather than creating a map for the sake of ticking off a day, I’d like to spend more time on each individual map and delve a bit deeper into some of the new packages I find.\r\nThanks to Topi Tjukanov for creating this challenge a few years ago, and well done to everyone who participated in this year’s challenge whether you made one or thirty maps in November.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-12-01-30-day-map-challenge-2021/images/maps_preview.png",
    "last_modified": "2021-12-18T14:58:09+00:00",
    "input_file": {},
    "preview_width": 1111,
    "preview_height": 794
  },
  {
    "path": "posts/2021-10-06-detecting-demand-outliers-in-transport-systems/",
    "title": "Detecting demand outliers in transport systems",
    "description": "An overview of my PhD thesis entitled \"Detecting demand outliers in transport systems\".",
    "author": [
      {
        "name": "Nicola Rennie",
        "url": {}
      }
    ],
    "date": "2021-10-06",
    "categories": [],
    "contents": "\r\nI recently completed my PhD at STOR-i CDT at Lancaster University. My thesis was titled “Detecting demand outliers in transport systems” and here I’ll (try to) give a brief overview of the work I’ve done in the last three years. The final version of my thesis can be found here.\r\nWhat are demand outliers?\r\nAn outlier is generally considered an abnormal event that doesn’t fit with the pattern of events normally observed. In the transport setting, demand outliers might mean that there are a lot more (or less) passengers than normal, or that they book earlier than normal, or that passengers are willing to pay more than they normally would for the same ticket. There are many things that can cause these changes in demand such as, football matches, weather, or public holidays. Some of these events e.g. Christmas, are known about in advance and can be accounted for in the planning process. Others are not known about. And it’s these changes in demand that we want to identify. Ideally, they’d be identified as early as possible, in order for the transport company to take action.\r\nIt’s important to detect changes in demand for multiple reasons. Transport companies set prices and ticket availability based on forecasts of demand. If the demand no longer matches the forecasts, then the prices that have been set are no longer optimal. Then transport companies lose revenue. It could also result in transport services being busier than expected. If you’ve ever gotten on a packed train and been unable to get a seat, you know that incorrectly managed demand isn’t desirable for passengers either.\r\nAt the moment, many transport companies employ analysts to monitor the number of bookings. However, as human beings, we’re not very good at spotting things by eye, and we tend to see patterns that don’t exist. My research develops a statistical method to identify demand outliers and send alerts to analysts.\r\nSo, how do we find the outliers?\r\nMost transport providers store information about bookings as a time series. For example, for train ABC departing on January 31 at 10:00, there is a series of observations of how many passengers had booked tickets by 3 months per departure, 1 month before departure, 1 week before departure … You get the idea. *Note: I’ll mainly be talking about trains here, but it’s all generalisable to other types of transport systems.\r\nSo for a set of departures, we would have a collection of time series that might look a bit like this:\r\n\r\n\r\n\r\nTo detect outliers within this set of time series, we use functional analysis. Functional analysis treats each time series of bookings as an observation of a continuous function. We calculate the functional depth of the time series of bookings for each train. I won’t go into all of the details about the equations for calculating the functional depth because they’re not very nice. But generally, depth measures provide us with an ordering of the time series – where the time series closest to the centre i.e., the median, has the highest depth, and that in the tails of the distribution i.e. outliers, have low depth. This allows to consider both changes in magnitude (e.g. a big increase in bookings), and shape of booking patterns (e.g. passengers booking earlier than normal). Outliers are detected by setting a threshold for the functional depth. Any time series with a functional depth below that threshold is classified as an outlier.\r\nOf course, we don’t just want to identify demand outliers in historic data (although this can still be beneficial on its own). We want to identify these outliers as they are happening, so that an analyst can make an adjustment. We found that forecasting the bookings still to come in, and performing the outlier detection on the forecasted bookings, helped us to identify the outliers earlier.\r\nThinking about transport systems\r\nThe vast majority of, if not all, transport systems do not simply consist of a single journey from A to B. There are often many places where passengers can start and end their journey, and multiple combinations to get between the two. It’s quite unlikely that any demand changes will only affect one single part of the transport network e.g. a single leg of a train journey. It’s also quite unlikely that the entire network will be affected by demand changes in the same way at the same time. Before even thinking about demand outliers, we developed a method split up the network into clusters that experience demand in similar ways. Our outlier detection method could then be applied jointly to legs in the same cluster which are likely to share common outliers.\r\n\r\n\r\n\r\nDuring my PhD, I collaborated with Deutsche Bahn, the German rail provider, and was able to test the methods developed on their data. We tested our methodology on a section of the Deutsche Bahn network consisting of two train lines - (i) from Munich to Hamburg and (ii) from Basel in Switzerland to Berlin. Generally, legs in the same train line were clustered together, and the edges of the clusters coincided with major train stations.\r\nA venture into bike-sharing\r\nOf course, it’s not all about trains. There are many other industries where detecting and accounting for systematic changes of demand is of interest. One of those industries is bike-sharing – where members of the public can pick-up a bike at a terminal and return it to any other terminal. Most bike-sharing systems are located in cities. Since some areas of a city are more populous than others, the bikes must be redistributed from the terminals that are commonly used as drop-offs to those that are commonly used for pick-ups. Although, a responsive approach could be taken to redistributing bikes i.e. only sending drivers to a terminal when it is full or empty, this isn’t very efficient.\r\n\r\n\r\n\r\nIf we are able to identify and predict when unusual demand patterns occur, bike-sharing companies can better organise their resources. A case study of the Capital Bikeshare system in Washington D.C. finds that there are spatial and temporal patterns to the outliers that occur.\r\nFinal Thoughts\r\nOverall, a key finding of my thesis is that functional data analysis is a very powerful tool for identifying demand outliers. However, features of the data such as network effects or seasonal patterns need to be taken into account first. More research into how an outlier-based alert system could be implemented in an automated way is still needed.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-06-detecting-demand-outliers-in-transport-systems/images/db.png",
    "last_modified": "2021-12-18T14:59:15+00:00",
    "input_file": {},
    "preview_width": 700,
    "preview_height": 500
  },
  {
    "path": "posts/2021-09-13-viz-for-social-good/",
    "title": "Viz For Social Good",
    "description": "Viz For Social Good volunteers create informative and impactful data visualizations for mission-driven organizations across the globe.",
    "author": [
      {
        "name": "Nicola Rennie",
        "url": {}
      }
    ],
    "date": "2021-09-13",
    "categories": [],
    "contents": "\r\nViz For Social Good volunteers create informative and impactful data visualizations for mission-driven organizations across the globe. Check out the organisation here.\r\nCode available at: github.com/nrennie/Viz_For_Social_Good\r\nVFSG: Visualize Our Community\r\nNon-profits around the world are driving positive social change but some of them lack the in-house resources to effectively tell their story with the data they have. Viz For Social Good (VFSG) helps non-profits thrive by connecting talented community members with organizations in need of data visualization skill sets.\r\n\r\n\r\n\r\nIn November 2021, Viz For Social Good ran a community poll, the results of which will help shape their diversity & inclusion efforts. 224 people responded from 38 different countries.\r\nSunny Street\r\nSunny Street is changing the world by providing healthcare to the most vulnerable people in Eastern Australia. One conversation between a Sunny Street volunteer and a patient can change the course of both of their lives.\r\n\r\n\r\n\r\nAlthough the Covid-19 pandemic caused many clinics to be cancelled, Sunny Street volunteers had the same (or more) conversations and consultations. There has been little change in patient demographic throughout the pandemic.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-09-13-viz-for-social-good/images/sunny_street.png",
    "last_modified": "2021-12-18T14:57:03+00:00",
    "input_file": {},
    "preview_width": 1111,
    "preview_height": 794
  },
  {
    "path": "posts/2021-05-04-dubois-challenge/",
    "title": "DuBois Challenge",
    "description": "The DuBois Challenge is part of a celebration of the data visualization legacy of W.E.B DuBois which attempts to recreate the visualizations from the 1900 Paris Exposition using modern tools.",
    "author": [
      {
        "name": "Nicola Rennie",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [],
    "contents": "\r\nThe DuBois Challenge is part of a celebration of the data visualization legacy of W.E.B DuBois which attempts to recreate the visualizations from the 1900 Paris Exposition using modern tools. Check out the challenge here.  \r\nCode available at: github.com/nrennie/dubois_challenge.\r\nChallenge 1\r\n\r\n\r\n\r\nChallenge 2\r\n\r\n\r\n\r\nChallenge 3\r\n\r\n\r\n\r\nChallenge 4\r\n\r\n\r\n\r\nChallenge 5\r\n\r\n\r\n\r\nChallenge 6\r\n\r\n\r\n\r\nChallenge 7\r\n\r\n\r\n\r\nChallenge 8\r\n\r\n\r\n\r\nChallenge 9\r\n\r\n\r\n\r\nChallenge 10\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-04-dubois-challenge/images/cover.jpg",
    "last_modified": "2021-12-18T15:00:32+00:00",
    "input_file": {}
  }
]
